{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Makarova Evgeniia\n",
    "#### Alejandro Pereña López\n",
    "\n",
    "# Practica 1. Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 1: Particionado\n",
    "Análisis de las dos estrategias de particionado propuestas: simple, y cruzada, para los conjuntos propuestos: german y tic-tac-toe. El análisis consiste en una descripción de los índices de train y test devueltos por cada uno de los métodos de particionado, junto con un comentario sobre las ventajas/desventajas de cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from Datos import *\n",
    "import EstrategiaParticionado\n",
    "import Clasificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validación simple__: Este metodo de particionado divide los datos en 2 partes dada la proporción de datos test y train. Antes de la división los ids de las filas están mezcladas de manera aleatoria para asegurarse que los datos en train and test no esten en el mismo orden que  en el conjunto de datos original (por si están ordenados por clases o algún atributo.\n",
    "\n",
    "__Ventajas__: Implementación simple y rápida\n",
    "\n",
    "__Desventajas__: Si el conjunto de datos es pequeño quedan pocos datos para la validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [8, 9, 10, 11, 12, 15, 17, 19, 24, 25, 26, 28, 29, 31, 33, 34, 35, 46, 52, 55, 62, 65, 67, 68, 73, 74, 79, 83, 84, 89, 93, 94, 99, 101, 104, 108, 109, 112, 123, 127, 128, 134, 136, 141, 149, 151, 153, 154, 161, 164, 165, 167, 169, 175, 178, 180, 182, 183, 186, 189, 190, 191, 192, 204, 207, 208, 215, 216, 219, 227, 232, 234, 239, 243, 249, 257, 259, 262, 264, 265, 266, 269, 273, 275, 276, 286, 288, 290, 291, 292, 297, 302, 308, 309, 313, 314, 316, 321, 323, 324, 328, 331, 333, 340, 342, 350, 352, 364, 365, 367, 369, 371, 374, 377, 390, 394, 395, 396, 399, 400, 404, 405, 407, 414, 418, 420, 422, 424, 426, 434, 436, 448, 451, 457, 461, 464, 469, 472, 473, 474, 475, 478, 481, 482, 483, 490, 492, 493, 496, 498, 499, 502, 507, 513, 517, 524, 527, 531, 533, 538, 544, 550, 562, 563, 564, 574, 575, 577, 580, 585, 587, 588, 595, 596, 600, 602, 603, 609, 611, 616, 624, 626, 634, 635, 637, 643, 646, 648, 649, 650, 656, 660, 667, 669, 675, 678, 679, 683, 686, 687, 688, 691, 695, 698, 704, 705, 706, 707, 712, 717, 718, 721, 723, 728, 729, 733, 736, 737, 738, 739, 743, 744, 746, 750, 753, 756, 759, 761, 762, 764, 767, 771, 773, 775, 778, 784, 788, 790, 801, 807, 812, 815, 817, 819, 820, 823, 826, 827, 832, 836, 839, 846, 848, 851, 854, 856, 861, 864, 871, 872, 877, 888, 889, 890, 895, 896, 898, 902, 903, 906, 907, 909, 913, 916, 917, 923, 927, 930, 931, 934, 935, 938, 939, 944, 946, 955, 956]\n"
     ]
    }
   ],
   "source": [
    "dataset=Datos('tic-tac-toe.data')\n",
    "estrategia=EstrategiaParticionado.ValidacionSimple(0.3, 1)\n",
    "# 0.3 = test_proportion, 1 = n_iters\n",
    "parts = estrategia.creaParticiones(dataset.datos)\n",
    "\n",
    "print(\"Test: \", parts[0].indicesTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para extraer los datos se utiliza el metodo extraeDatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' 'x' 'x' ... 'o' 'o' 'positive']\n",
      " ['x' 'x' 'x' ... 'o' 'b' 'positive']\n",
      " ['x' 'x' 'x' ... 'b' 'o' 'positive']\n",
      " ...\n",
      " ['x' 'o' 'x' ... 'x' 'o' 'negative']\n",
      " ['o' 'x' 'o' ... 'o' 'x' 'negative']\n",
      " ['o' 'x' 'o' ... 'o' 'x' 'negative']]\n"
     ]
    }
   ],
   "source": [
    "train=dataset.extraeDatos(parts[0].indicesTrain)\n",
    "test=dataset.extraeDatos(parts[0].indicesTest)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validación cruzada__: En este tipo de validación el conjunto de datos de divide de manera aleatoria en N grupos, y uno de los grupos se utiliza para test y otros N-1 para train. De esta manera generamos N diferentes subconjuntos de train/test.\n",
    "![alt text](K-fold_cross_validation.jpg \"K-Fold Cross Validation\")\n",
    "\n",
    "__Ventajas__:Se utiliza el conjunto completo de datos para entrenamiento y para la validación y se puede generar más metricas para ver si el modelo el robusto.\n",
    "\n",
    "__Desventajas__: El algoritmo hay que repetir N veces, lo que conlleva mayor coste computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ids con segundo grupo asignado como test y train el resto:\n",
      "[7, 10, 12, 25, 33, 34, 36, 38, 43, 49, 51, 54, 55, 79, 85, 87, 91, 95, 96, 102, 105, 106, 107, 113, 114, 115, 119, 120, 121, 123, 125, 127, 130, 132, 136, 137, 140, 142, 150, 154, 155, 160, 163, 167, 171, 172, 178, 179, 184, 189, 192, 193, 194, 198, 202, 208, 211, 214, 216, 225, 227, 228, 231, 233, 236, 238, 256, 258, 259, 261, 268, 273, 275, 276, 280, 282, 286, 288, 292, 297, 298, 300, 305, 323, 326, 329, 331, 332, 333, 335, 336, 337, 338, 341, 346, 347, 352, 356, 358, 369, 378, 385, 395, 399, 400, 403, 422, 423, 426, 439, 442, 449, 451, 453, 455, 457, 458, 462, 463, 467, 468, 469, 472, 476, 482, 498, 504, 515, 518, 522, 524, 525, 526, 527, 536, 537, 541, 544, 546, 550, 557, 562, 564, 573, 577, 580, 583, 585, 593, 610, 617, 618, 619, 622, 626, 628, 629, 631, 637, 643, 644, 647, 649, 652, 654, 661, 662, 663, 667, 668, 669, 673, 674, 678, 685, 686, 687, 688, 689, 691, 692, 700, 702, 704, 708, 711, 714, 715, 717, 735, 743, 744, 748, 749, 753, 755, 760, 765, 770, 773, 778, 784, 791, 797, 798, 801, 809, 810, 813, 814, 824, 837, 838, 842, 844, 847, 851, 855, 860, 861, 863, 864, 866, 874, 878, 882, 901, 902, 913, 919, 922, 923, 937, 939, 940, 941, 948, 949, 953, 954]\n"
     ]
    }
   ],
   "source": [
    "estrategia=EstrategiaParticionado.ValidacionCruzada(4)\n",
    "# 4 = n_partitions\n",
    "parts = estrategia.creaParticiones(dataset.datos)\n",
    "print(\"Test ids con segundo grupo asignado como test y train el resto:\")\n",
    "print(parts[1].indicesTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 2: Naive-Bayes\n",
    "Tabla con los resultados de la ejecución para los conjuntos de datos analizados (tic-tac-toe y german). Considerar los dos tipos de particionado.\n",
    "Los resultados se refieren a las tasas de error/acierto. Es importante mostrar todos los resultados agrupados en una tabla para facilitar su evaluación.\n",
    "Breve análisis de los resultados anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacion simple:\n",
      "Tic tac toe error (sin laplace) 0.28222996515679444\n",
      "Tic tac toe error (con laplace) 0.313588850174216\n",
      "German error (sin laplace) 0.22666666666666666\n",
      "German error (con laplace) 0.25333333333333335\n"
     ]
    }
   ],
   "source": [
    "print(\"Validacion simple:\")\n",
    "tictac=Datos('tic-tac-toe.data')\n",
    "#test_proportion = 0.3, n_iters = 1\n",
    "estrategia=EstrategiaParticionado.ValidacionSimple(0.3, 1)\n",
    "clasificador=Clasificador.ClasificadorNaiveBayes(False)\n",
    "errores=clasificador.validacion(estrategia,tictac,clasificador)\n",
    "print(\"Tic tac toe error (sin laplace)\", errores)\n",
    "estrategia=EstrategiaParticionado.ValidacionSimple(0.3, 1)\n",
    "clasificador=Clasificador.ClasificadorNaiveBayes(True)\n",
    "errores=clasificador.validacion(estrategia,tictac,clasificador)\n",
    "print(\"Tic tac toe error (con laplace)\", errores)\n",
    "\n",
    "\n",
    "german=Datos('german.data') \n",
    "estrategia=EstrategiaParticionado.ValidacionSimple(0.3, 1)\n",
    "clasificador=Clasificador.ClasificadorNaiveBayes(False)\n",
    "errores=clasificador.validacion(estrategia,german,clasificador)\n",
    "print(\"German error (sin laplace)\", errores)\n",
    "estrategia=EstrategiaParticionado.ValidacionSimple(0.3, 1)\n",
    "clasificador=Clasificador.ClasificadorNaiveBayes(True)\n",
    "errores=clasificador.validacion(estrategia,german,clasificador)\n",
    "print(\"German error (con laplace)\", errores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacion cruzada:\n",
      "Tic-tac-toe error (sin laplace) 0.2891692817294282\n",
      "Tic-tac-toe error (con laplace) 0.30478992329149235\n",
      "german error (sin laplace) 0.237\n",
      "german error (con laplace) 0.236\n"
     ]
    }
   ],
   "source": [
    "print(\"Validacion cruzada:\")\n",
    "#n_partitions = 4\n",
    "estrategia=EstrategiaParticionado.ValidacionCruzada(4)\n",
    "clasificador=Clasificador.ClasificadorNaiveBayes(False)\n",
    "errores=clasificador.validacion(estrategia,tictac,clasificador)\n",
    "print(\"Tic-tac-toe error (sin laplace)\", errores)\n",
    "estrategia=EstrategiaParticionado.ValidacionCruzada(4)\n",
    "clasificador=Clasificador.ClasificadorNaiveBayes(True)\n",
    "errores=clasificador.validacion(estrategia,tictac,clasificador)\n",
    "print(\"Tic-tac-toe error (con laplace)\", errores)\n",
    "\n",
    "estrategia=EstrategiaParticionado.ValidacionCruzada(4)\n",
    "clasificador=Clasificador.ClasificadorNaiveBayes(False)\n",
    "errores=clasificador.validacion(estrategia,german,clasificador)\n",
    "print(\"german error (sin laplace)\", errores)\n",
    "estrategia=EstrategiaParticionado.ValidacionCruzada(4)\n",
    "clasificador=Clasificador.ClasificadorNaiveBayes(True)\n",
    "errores=clasificador.validacion(estrategia,german,clasificador)\n",
    "print(\"german error (con laplace)\", errores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error con validación simple__\n",
    "\n",
    "|Dataset|tic-tac-toe|german|\n",
    "|-------|-----------|------|\n",
    "|Error (Sin Laplace)| 0.282| 0.226|\n",
    "|Error (Laplace)| 0.313| 0.253|\n",
    "\n",
    "__Error con validación cruzada (media)__\n",
    "\n",
    "|Dataset|tic-tac-toe|german|\n",
    "|-------|-----------|------|\n",
    "|Error (Sin Laplace)| 0.289 | 0.237|\n",
    "|Error (Laplace)| 0.304| 0.236|\n",
    "\n",
    "\n",
    "El error aplicando y no aplicando Laplace para estos conjuntos de datos es parecido, no influye mucho a la precisión de clasificador. \n",
    "El error de validación cruzada es más bajo porque hemos utilzado más datos para entrenamiento en cada de sus iteraciones (75% vs 70% en validación simple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 3: Scikit-Learn\n",
    "Incluir los mismos resultados que en el apartado 2 pero usando los métodos del paquete scikit-learn. Comparar y analizar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error validación simple:\n",
      "Bayes gaussiano:\n",
      "Tic tac toe: 0.28222996515679444\n",
      "German: 0.25\n",
      "Bayes multinomial:\n",
      "Tic tac toe: 0.3344947735191638\n",
      "German: 0.24\n"
     ]
    }
   ],
   "source": [
    "#bayes type = gaussian or multinomial\n",
    "def error_sklearn_bayes(train, test, bayes_type):\n",
    "    #Preparando los datos conviertiendo datos categoricos a numericos\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    train_a=np.empty([train.shape[0], train.shape[1]])\n",
    "    test_a=np.empty([test.shape[0], test.shape[1]])\n",
    "    for i in range(train.shape[1]):\n",
    "        train_column=train[:,i]\n",
    "        train_column=le.fit_transform(train_column)\n",
    "        train_a[:,i]=np.transpose(train_column)\n",
    "    for i in range(test.shape[1]):    \n",
    "        test_column=test[:,i]\n",
    "        test_column=le.fit_transform(test_column)\n",
    "        test_a[:,i]=np.transpose(test_column)\n",
    "\n",
    "\n",
    "    input_train=[]\n",
    "    for row in range(train_a.shape[0]):\n",
    "        input_train.append(train_a[row,0:-1])\n",
    "    classes_encoded=train_a[:,-1]\n",
    "\n",
    "    validation=[]\n",
    "    real_class=[]\n",
    "    for row in range(test_a.shape[0]):\n",
    "        validation.append(test_a[row,0:-1])\n",
    "        real_class.append(test_a[row,-1])\n",
    "\n",
    "\n",
    "    if bayes_type==\"gaussian\":\n",
    "        clf = GaussianNB()\n",
    "    else:\n",
    "        clf = MultinomialNB()\n",
    "            \n",
    "\n",
    "\n",
    "    clf.fit(input_train, classes_encoded)\n",
    "\n",
    "    error=0\n",
    "    for r in range(len(validation)):\n",
    "        predicted=clf.predict([validation[r]])\n",
    "        if predicted!=real_class[r]:\n",
    "            error+=1\n",
    "    error=error/len(validation)\n",
    "    #print(\"Error validación simple:\", error)\n",
    "    #print(\"Fit score:\", clf.score(input_array, classes_encoded))\n",
    "    return(error)\n",
    "\n",
    "print(\"Error validación simple:\")\n",
    "print(\"Bayes gaussiano:\")\n",
    "print(\"Tic tac toe:\", error_sklearn_bayes(train_tic, test_tic, \"gaussian\"))\n",
    "print(\"German:\", error_sklearn_bayes(train_german, test_german , \"gaussian\"))\n",
    "print(\"Bayes multinomial:\")\n",
    "print(\"Tic tac toe:\", error_sklearn_bayes(train_tic, test_tic, \"multinomial\"))\n",
    "print(\"German:\", error_sklearn_bayes(train_german, test_german , \"multinomial\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error validación cruzada:\n",
      "Bayes gaussiano\n",
      "Tic-tac-toe [0.2916666666666667, 0.275, 0.24686192468619247, 0.30962343096234307] Mean:  0.28078800557880057 Std: 0.023099280277892393\n",
      "German [0.292, 0.268, 0.232, 0.276] Mean:  0.267 Std: 0.021977260975835904\n",
      "Bayes multinomial\n",
      "Tic-tac-toe [0.325, 0.3375, 0.3138075313807531, 0.3891213389121339] Mean:  0.3413572175732218 Std: 0.02882201064606139\n",
      "German [0.3, 0.296, 0.26, 0.272] Mean:  0.28200000000000003 Std: 0.01661324772583614\n"
     ]
    }
   ],
   "source": [
    "##Cruzada\n",
    "partitions=4\n",
    "#Tic tac\n",
    "#line_ids_tic=validacion_cruzada(rows_tictac,partitions)\n",
    "#Utilizamos las mismas particiones que en apartado 2\n",
    "error_cross_tictac_g=[]\n",
    "error_cross_tictac_m=[]\n",
    "for i in range(partitions):\n",
    "    line_ids_test=line_ids_tic[i]['Test']\n",
    "    line_ids_train=line_ids_tic[i]['Train']\n",
    "    train=tictac.extraeDatos(line_ids_train)\n",
    "    test=tictac.extraeDatos(line_ids_test)\n",
    "    error_cross_tictac_g.append(error_sklearn_bayes(train, test, \"gaussian\"))\n",
    "    error_cross_tictac_m.append(error_sklearn_bayes(train, test, \"multinomial\"))\n",
    "\n",
    "#line_ids_german=validacion_cruzada(rows_german,partitions)\n",
    "error_cross_german_g=[]\n",
    "error_cross_german_m=[]\n",
    "for i in range(partitions):\n",
    "    line_ids_test=line_ids_german[i]['Test']\n",
    "    line_ids_train=line_ids_german[i]['Train']\n",
    "    train=german.extraeDatos(line_ids_train)\n",
    "    test=german.extraeDatos(line_ids_test)\n",
    "    error_cross_german_g.append(error_sklearn_bayes(train, test,  \"gaussian\"))\n",
    "    error_cross_german_m.append(error_sklearn_bayes(train, test,  \"multinomial\"))\n",
    "    \n",
    "print(\"Error validación cruzada:\")\n",
    "print(\"Bayes gaussiano\")\n",
    "print(\"Tic-tac-toe\", error_cross_tictac_g, \"Mean: \", np.mean(error_cross_tictac_g), \"Std:\", np.std(error_cross_tictac_g))\n",
    "print(\"German\", error_cross_german_g, \"Mean: \", np.mean(error_cross_german_g), \"Std:\", np.std(error_cross_german_g))\n",
    "\n",
    "print(\"Bayes multinomial\")\n",
    "print(\"Tic-tac-toe\", error_cross_tictac_m, \"Mean: \", np.mean(error_cross_tictac_m), \"Std:\", np.std(error_cross_tictac_m))\n",
    "print(\"German\", error_cross_german_m, \"Mean: \", np.mean(error_cross_german_m), \"Std:\", np.std(error_cross_german_m))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultados:__\n",
    "\n",
    "\n",
    "__Error con validación simple__\n",
    "\n",
    "\n",
    "|Dataset|tic-tac-toe|german|\n",
    "|-------|-----------|------|\n",
    "|Clasificador de práctica | 0.344| 0.272|\n",
    "|SKlearn Gaussian|0.282|0.25|\n",
    "|SKlearn multinomial|0.335|0.24|\n",
    "\n",
    "\n",
    "__Error con validación cruzada__\n",
    "\n",
    "|Dataset|tic-tac-toe|german|\n",
    "|-------|-----------|------|\n",
    "||Error Promedio||\n",
    "|Clasificador de práctica| 0.279 | 0.257|\n",
    "|SKlearn Gaussian| 0.281 | 0.267|\n",
    "|SKlearn multinomial| 0.341 | 0.282|\n",
    "||Desviación estandar||\n",
    "|Clasificador de práctica| 0.0239| 0.0172|\n",
    "|SKlearn Gaussian| 0.0231| 0.022|\n",
    "|SKlearn multinomial| 0.0288| 0.0166|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 4: Evaluación de hipótesis mediante Análisis ROC\n",
    "__Matriz de confusión__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "Tic tac toe:\n",
      "[[161.  58.]\n",
      " [ 28.  40.]]\n",
      "TPR: 0.85 FNR:  0.15 FPR:  0.59 TNR:  0.41\n",
      "German:\n",
      "[[192.  39.]\n",
      " [ 29.  40.]]\n",
      "TPR: 0.87 FNR:  0.13 FPR:  0.49 TNR:  0.51\n"
     ]
    }
   ],
   "source": [
    "#positive and negative are the classes names that need to be compared\n",
    "def confusion_mx(dataset, train, test, laplace, positive, negative):\n",
    "    confusion_matrix=np.zeros([2,2])\n",
    "    for r in range(test.shape[0]):\n",
    "        predicted=naive_bayes(dataset, train, test[r][0:-1], laplace)\n",
    "        real=test[r][-1]\n",
    "        if predicted==positive:\n",
    "            if real==positive:\n",
    "                confusion_matrix[0,0]+=1\n",
    "            else: \n",
    "                confusion_matrix[0,1]+=1\n",
    "        else:\n",
    "            if real==negative:\n",
    "                confusion_matrix[1,1]+=1\n",
    "            else: \n",
    "                confusion_matrix[1,0]+=1\n",
    "\n",
    "    return(confusion_matrix)\n",
    "\n",
    "confusion_matrix_tic=confusion_mx(tictac, train_tic, test_tic, True, \"positive\", \"negative\")\n",
    "print(\"Confusion matrix\")\n",
    "print(\"Tic tac toe:\")\n",
    "print(confusion_matrix_tic)\n",
    "tp=confusion_matrix_tic[0,0]\n",
    "fn=confusion_matrix_tic[1,0]\n",
    "fp=confusion_matrix_tic[0,1]\n",
    "tn=confusion_matrix_tic[1,1]\n",
    "\n",
    "tpr=round(tp/(tp+fn),2)\n",
    "fnr=round(fn/(tp+fn),2)\n",
    "fpr=round(fp/(fp+tn),2)\n",
    "tnr=round(tn/(fp+tn),2)\n",
    "print(\"TPR:\", tpr, \"FNR: \", fnr, \"FPR: \", fpr, \"TNR: \", tnr)\n",
    "\n",
    "\n",
    "confusion_matrix_german=confusion_mx(german, train_german, test_german, True, 1, 2)\n",
    "print(\"German:\")\n",
    "print(confusion_matrix_german)\n",
    "tp=confusion_matrix_german[0,0]\n",
    "fn=confusion_matrix_german[1,0]\n",
    "fp=confusion_matrix_german[0,1]\n",
    "tn=confusion_matrix_german[1,1]\n",
    "\n",
    "tpr=round(tp/(tp+fn),2)\n",
    "fnr=round(fn/(tp+fn),2)\n",
    "fpr=round(fp/(fp+tn),2)\n",
    "tnr=round(tn/(fp+tn),2)\n",
    "print(\"TPR:\", tpr, \"FNR: \", fnr, \"FPR: \", fpr, \"TNR: \", tnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Matriz de confusión:__\n",
    "\n",
    "Tic tac toe\n",
    "\n",
    "||Real||\n",
    "|----|----|----|\n",
    "|Clase|Positivo|Negativo|\n",
    "|Positivo|161|58|\n",
    "|Negativo|28|40|\n",
    "\n",
    "\n",
    "|TPR|FNR|FPR|TNR|\n",
    "|---|---|---|---|\n",
    "|0.85|0.15|0.59|0.41|\n",
    "\n",
    "\n",
    "German\n",
    "\n",
    "||Real||\n",
    "|----|----|----|\n",
    "|Clase|1|2|\n",
    "|1|192|39|\n",
    "|2|29|40|\n",
    "\n",
    "|TPR|FNR|FPR|TNR|\n",
    "|---|---|---|---|\n",
    "|0.87|0.13|0.49|0.51|\n",
    "\n",
    "\n",
    "En ambos conjuntos de datos el clasificador tiene un ratio elevado para falsos positivos, tiene errores elevador en clasificación de clase 2 (negativos en tic-tac-toe y 2 en german)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Curvas ROC__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00621118 0.01242236 0.01242236 0.01863354 0.02484472\n",
      " 0.0310559  0.0310559  0.0310559  0.03726708 0.04347826 0.04968944\n",
      " 0.05590062 0.0621118  0.06832298 0.07453416 0.08074534 0.08695652\n",
      " 0.0931677  0.0931677  0.09937888 0.10559006 0.11180124 0.11801242\n",
      " 0.1242236  0.1242236  0.13043478 0.13664596 0.14285714 0.14906832\n",
      " 0.1552795  0.16149068 0.16770186 0.17391304 0.18012422 0.1863354\n",
      " 0.19254658 0.19875776 0.20496894 0.21118012 0.2173913  0.22360248\n",
      " 0.22981366 0.23602484 0.24223602 0.2484472  0.2484472  0.2484472\n",
      " 0.2484472  0.25465839 0.26086957 0.26708075 0.27329193 0.27950311\n",
      " 0.28571429 0.29192547 0.29813665 0.30434783 0.31055901 0.31677019\n",
      " 0.32298137 0.32919255 0.33540373 0.34161491 0.34782609 0.35403727\n",
      " 0.36024845 0.36645963 0.37267081 0.37267081 0.37267081 0.37888199\n",
      " 0.38509317 0.39130435 0.39751553 0.40372671 0.40993789 0.41614907\n",
      " 0.42236025 0.42857143 0.43478261 0.44099379 0.44720497 0.44720497\n",
      " 0.45341615 0.45962733 0.46583851 0.47204969 0.47204969 0.47204969\n",
      " 0.47826087 0.48447205 0.48447205 0.48447205 0.48447205 0.48447205\n",
      " 0.49068323 0.49689441 0.49689441 0.50310559 0.50931677 0.51552795\n",
      " 0.52173913 0.52795031 0.52795031 0.52795031 0.53416149 0.54037267\n",
      " 0.54658385 0.55279503 0.55900621 0.56521739 0.57142857 0.57142857\n",
      " 0.57763975 0.58385093 0.59006211 0.59627329 0.60248447 0.60869565\n",
      " 0.61490683 0.62111801 0.62732919 0.63354037 0.63975155 0.64596273\n",
      " 0.65217391 0.65838509 0.66459627 0.67080745 0.67701863 0.68322981\n",
      " 0.68322981 0.68944099 0.69565217 0.70186335 0.70807453 0.71428571\n",
      " 0.71428571 0.72049689 0.72670807 0.72670807 0.73291925 0.73291925\n",
      " 0.73913043 0.74534161 0.7515528  0.75776398 0.76397516 0.77018634\n",
      " 0.77639752 0.77639752 0.7826087  0.78881988 0.79503106 0.80124224\n",
      " 0.80745342 0.8136646  0.81987578 0.82608696 0.83229814 0.83850932\n",
      " 0.8447205  0.85093168 0.85714286 0.86335404 0.86956522 0.8757764\n",
      " 0.88198758 0.88819876 0.89440994 0.90062112 0.9068323  0.91304348\n",
      " 0.91925466 0.92546584 0.93167702 0.9378882  0.94409938 0.95031056\n",
      " 0.95652174 0.96273292 0.9689441  0.97515528 0.98136646 0.98757764\n",
      " 0.98757764 0.99378882 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ba75a6ce88>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5wU5Z3v8c+PgQFRQAVckLuRxAyOAo4QxQuGaNB1IXpIxMtGWfGyiboxXtZkDTHEVaKJuyZeIiuXjZGA4oKcBI85KqgooHCciECMSEAGUceR+0Uu+Z0/qnpsm56enkt1T3d936/XvKa76unq31PdXb96nqp6ytwdERGJr1b5DkBERPJLiUBEJOaUCEREYk6JQEQk5pQIRERiTolARCTmlAhEADPra2ZuZq2buJyVZjY8fGxmNs3MNpvZa2Z2upm93SwBf/49p5vZnc293KTlrzOzrzXidcPNrCqKmOp538PNbK2ZDWrk63ub2Q4zK2nu2FoqJYJmYmaXmNmy8Au0ycyeMbPT8h1XJuGGb2cY80Yzuy/1y29m54cbsZ1mVmNmj5tZz5Qy3c1sSljv7Wb2ZzP7iZkdmtsa5Z+7D3D3heHT04CzgZ7uPsTdX3b3L+Uvuti4D7jL3d/IpnBqonP399z9MHc/EFmELYwSQTMws+8D/wncBfwd0Bt4CBjdiGU1aY+0EU5098OAM4GLgH9KimUMMAO4H+gCDAA+BRaZ2RFhmSOBxcAhwCnu3oFg43c48IUoA8/DumqoPsA6d9+Z70DSKYD1l5XkephZB+A1d380jyEVHnfXXxP+gE7ADuCbGcpMB+5Mej4cqEp6vg74V+BNgg3t7cDslGXcD/wyfDwOWA1sB9YC1ySV6wL8HtgCfAK8DLSqIy4Hjk16/gTwYPjYgPXArSmvaQW8BUwMn98JrKjrPdK8Z9/wfa8G3gc2ATclzR9CkFi2hPMeAEpTYv4u8A7w16R1swHYBiwHTs/w/ocAvwjrthVYFE5LxNW6Kes4/Cy/BlwJ7AEOhN+Pn6T53HsB/wNUAzXAA+H0LwAvhNM+Bh4HDk963SDg/4WxzQJmpny/rgLWhLHNA47OtP7SrKN/DNdPDfBviTolff63Ae+G858AjqxjOan1TbxuO7AKuCDD53QHMDus3/awvidm+M20rm/54XpZnTR/MPAY8Ddgd/g53Zrmu3AkMI3g+7oZmBtOPyL8HlSH039P0PrL+3apoX95D6DQ/4CRwP7El6aOMtOpPxFUhhuGQwj2JHcBHcP5JQQbxa+Ez/8+3FgYwZ78LmBwOO9u4NdAm/DvdMDqiKs2EQDHhe9xY9JzB/qled1PgMXh4yXATxqwvhI/st8BhwLl4Q8psaE5CfhK+MPuG/5wv5cS8/8Nf5yHhNMuAzqHr7kJ+ABoV8f7PwgsBHqE6/VUoG2aH3+j1jGf32heASxK97mH7/0n4D/C9dAOOC2cdyxBq6ot0BV4CfjPcF4pwUb6xvC9xwD7CL9fwFcJksfg8PW/Al7KtP5S1k8ZwQbxjPD19xF8vxN1+l74mfcM5z8C/K6OdV1b3/D5N4GjCZLJRcBOoHsdr70jrNeYsJ43A38F2qT7zYTTLgo/14OWH773RuDk8DM9FuiT+pmlfEcT34U/ECSkI8JYzgyndwb+F9Ae6AA8SZgkCu0v7wEU+h9wKfBBPWWmU38i+KeU1ywCvh0+Pht4N8Py5wL/Ej6eCDxN0p5+htc5wV70Tj7bOLcN550WTjtogwpcC7wTPn4HuLYB6yvxIzsuado9wJQ6yn8PmJMS81freY/NJO09Jk1vRbDnl27e5378jV3HZJ8ITiFIgHXuQCS97hvAG+HjMwj2TC1p/qt8lgimAPckzTuMYIPaN5v1B0wAZiY9PxTYm1Sn1cCIpPndw+UfVI/U73ma+ZXA6Drm3QEsSfnsNhG29kjzm8m0fODZxOeX6TNL/S6E9fsbcEQWn9NAYHO2v4WW9KdjBE1XA3Rphv7WDSnPZwAXh48vCZ8DYGbnmtkSM/vEzLYA5xF0VwDcS9At8MfwzInb6nnfwQQbi4uAoQQ/fAj2KiH4IaTqnjS/po4y9Umu73qCPUXM7Itm9nsz+8DMthEcd+mS4bWY2U1mttrMtobro1Oa1xBOa0fQfZBRM6/jdHoB6919f5r3PsrMZoYH8LcBv01676OBjR5ueULrkx4fnfzc3XcQfEY9ksqkfteSHZ0834PjGzVJ8/sAc8xsS7heVhN0f/1dhmUm6vVtM6tMeu3xpP+cDorT3f8GVIXxpa2HmV0UfmYbzGwdQas2sfxeZPG5p9EL+MTdN6epT3sze8TM1oef00vA4YV4tpESQdMtJugL/kaGMjsJmo8J3dKU8ZTnTwLDwzN0LiBMBGbWFngK+Dnwd+5+ODCfoLmLu29395vc/RjgH4Dvm9mITBXwwBNhXSaEk98m+OF9M7msmbUiaA4/H056DrggnN4QvZIe9ybYywV4GPgz0N/dOwI/TNQtOeSkeE4n6Cv+FsFe2+EEff+pr4Egee2hnoPYUazjNDYAvevYgbiboI4nhOvgsqT6bAJ6mFly/XonPX6fYGOdqMuhBF0YG5PKpH7Xkm0i6bMxs/bh65PjPtfdD0/6a+fuG1MXlMzM+gD/BVwHdA7X6Vuk/5wSkuNoRdAd9X7S/OTvQS+Clvd17t7L3fsSfIcTy99A3Z97pvWxATjSzA5PM+8m4EvA0PBzOiMRTobltUhKBE3k7lsJNp4Pmtk3wr2ENuEe5T1hsUrgPDM70sy6EXR31LfcaoK+7GkEB/VWh7NKCfpmq4H9ZnYucE7ideHpnseGG4ptBHtr2Z4GNwm42sy6hXucNwO3h6fGHhLG/ijQkaBvG4I+5I7Af4c/dsysR3gq6gkZ3utH4boaQHBgdlY4vUMY9w4zOw7453pi7kDQh10NtDazCWE8Bwn3KqcC95nZ0WZWYmanhBv+ZFGu44TXCDa6k8zsUDNrZ2bDkuq0A9hiZj2AW5Jetzis7w1m1trMLiQ4wJ4wAxhnZgPDet0FLHX3dVnGNRs438xOM7NSgm6w5O3Er4F/T/qsu5pZNmfHHUqwwa0OXzeOoEWQyUlmdmGYLL9HcFB4SR1lOxJsgHeGn+s4grPcEh4FbjazkyxwbKIOwIfAMekW6u6bgGeAh8zsiPC3ndjgdyDoatwSnj3343rq02IpETQDd78P+D7B2T7VBHsR1xH0K0NwZsKfCPoi/8hnG736zCA4A6W2W8jdtwM3EJytsZmg22he0mv6E+yl7yDYaDzkn53XXl89VgAvEm543H0WwRkkNxLsTa8iOJg9zN1rwjKfEBxw3QcsNbPtBK2FrQTdJ3V5MZz/PPBzd/9jOP3msE7bCfYg61tXzxL8UP9C0CWyh8xdHzcTnOX0OsFZNT8j5XcQ5TpOeo8DBK2JY4H3CFpfF4Wzf0LQZbeV4EDl/yS9bi9wIcHxh83ha5LnPw/8iKBFs4lgL3hsA+JaSXBW0Yzw9ZvD2BLuJ1gXfww/6yUEXYr1LXcVwdlaiwk2vOXAK/W87GmC+m0m+B5e6O77MsT9i3CZBy3f3Z8E/j2s13aC3+aR4ey7CXZ4tpjZzWkW/48E3+8/Ax/x2Y7cfxL8Hj4mWA//p576tFiJMx1EcsLM+vLZ2R8H9Y+LAJjZHQQH4y/LdyxxoBaBiEjMKRGIiMScuoZERGJOLQIRkZgruEGnunTp4n379s13GCIiBWX58uUfu3vXdPMKLhH07duXZcuW5TsMEZGCYmbr65qnriERkZhTIhARiTklAhGRmCu4YwTp7Nu3j6qqKvbs2ZPvUIpOu3bt6NmzJ23atMl3KCISkaJIBFVVVXTo0IG+ffvy+UEZpSncnZqaGqqqqujXr1++wxGRiETWNWRmU83sIzN7q475Zma/NLM1ZvammQ1u7Hvt2bOHzp07Kwk0MzOjc+fOammJFLkojxFMJ7iNY13OJRjFsT/B/WsfbsqbKQlEQ+tVpPhFlgjc/SWCYX7rMhr4TXhTlCUEd/ZpzJ2uRESK3pKHrmLJQ1dFsux8njXUg8+PG1/F52+nV8vMrjazZWa2rLq6OifBNURNTQ0DBw5k4MCBdOvWjR49etQ+P/XUU7Nezty5c1m1alWzxHTXXXc1y3JEpGXosGU1Hbasrr9gI+QzEaTrc0g7Ap67T3b3Cnev6No17RXSedW5c2cqKyuprKzk2muv5cYbb6x9/uqrr2a9HCUCEcmHfJ41VMXn71ubej/SonDYYYexY8cOAO655x4ee+wxWrVqxbnnnsukSZNqy7366qvMmzePF198kTvvvJOnnnqKF154gcmTJ7N3716OPfZYHnvsMdq3b8+HH37Itddey9q1awF4+OGHP9fyuO2229i9ezcDBw5kwIABPP7449x3331MnToVgPHjx/O97wU3Wfrtb3/LL3/5S/bu3cvQoUN56KGHKCkpuHtvixScGUvfY8er/8Ww3QuyKt9r77tsKM14u+1Gy2cimAdcZ2YzCW51tzW8P2iT/OR/r2TV+9uaHFyysqM78uN/GFB/wQyeeeYZ5s6dy9KlS2nfvj2ffPL5wyennnoqo0aN4vzzz2fMmDEAHH744Vx1VdAnePvttzNlyhSuv/56brjhBs4880zmzJnDgQMHahNNwqRJk3jggQeorKwEYPny5UybNo2lS5fi7gwdOpQzzzyTdu3aMWvWLF555RXatGnDd77zHR5//HG+/e1vN6muIrG2bBqsmF1vsRM3bWXA3hUArCwtr7f8htIvsKP/BU0OL53IEoGZ/Q4YDnQxsyqCGzu3AXD3XwPzgfMI7lu7i+AG5kXrueeeY9y4cbRv3x6AI488sp5XwFtvvcXtt9/Oli1b2LFjB1//+tcBeOGFF/jNb34DQElJCZ06dcq4nEWLFnHBBRdw6KGHAnDhhRfy8ssv06pVK5YvX87JJ58MwO7duznqqKMaXUcRIUgCH6yAbvVv3FeWljPgnCsZUJHfzV9kicDdL65nvhPcJLtZNXXPPSru3uBTMa+44grmzp3LiSeeyPTp01m4cGGj37uu6Zdffjl33313o5YrInXoVg7j/pCxyMRHFgMwq+KUXESUkcYaypFzzjmHqVOnsmvXLoCDuoYAOnTowPbt22ufb9++ne7du7Nv3z4ef/zx2ukjRozg4YeDyy4OHDjAtm0Hd4W1adOGffv2AXDGGWcwd+5cdu3axc6dO5kzZw6nn346I0aMYPbs2Xz00Ue1Ma1fX+dItSJSpJQIcmTkyJGMGjWKiooKBg4cyM9//vODyowdO5Z7772XQYMG8e677/LTn/6UoUOHcvbZZ3PcccfVlrv//vtZsGAB5eXlnHTSSaxcufKgZV199dWccMIJXHrppQwePJgrrriCIUOGMHToUMaPH8+gQYMoKyvjzjvv5JxzzuGEE07g7LPPZtOmJh+mEZECU3D3LK6oqPDUG9OsXr2aL3/5y3mKqPhp/Yo0wLS/D/7X0zV0UaJr6JrcdA2Z2XJ3r0g3Ty0CEZGYUyIQEYk5JQIRkZhTIhARiTklAhGRmFMiEBGJOSWCZvThhx9yySWXcMwxx3DSSSdxyimnMGfOnHyHJSKSkRJBM3F3vvGNb3DGGWewdu1ali9fzsyZM6mqqsrq9QcOHIg4QhGR9JQImskLL7xAaWkp1157be20Pn36cP3113PgwAFuueUWTj75ZE444QQeeeQRABYuXMhZZ53FJZdcQnl5OevWreO4445j/PjxHH/88Vx66aU899xzDBs2jP79+/Paa68B8Nprr3HqqacyaNAgTj31VN5++20Apk+fzoUXXsjIkSPp378/t956a+5XhIgUnHwOQx2NZ24LRv5rTt3K4dxJGYusXLmSwYMHp503ZcoUOnXqxOuvv86nn37KsGHDOOecc4Bgo/7WW2/Rr18/1q1bx5o1a3jyySeZPHkyJ598MjNmzGDRokXMmzePu+66i7lz53Lcccfx0ksv0bp1a5577jl++MMf8tRTTwFQWVnJG2+8Qdu2bfnSl77E9ddfT69evdLGJSICxZgIWojvfve7LFq0iNLSUvr06cObb77J7NnBGOVbt27lnXfeobS0lCFDhtCvX7/a1/Xr14/y8mD42gEDBjBixAjMrLbFkHj95ZdfzjvvvIOZ1Q4uB8GAdIlhqcvKyli/fr0SgYhkVHyJoJ4996gMGDCgdq8c4MEHH+Tjjz+moqKC3r1786tf/ar2fgIJCxcurL1HQELbtm1rH7dq1ar2eatWrdi/fz8AP/rRjzjrrLOYM2cO69atY/jw4WlfX1JSUvsaEZG66BhBM/nqV7/Knj17aoeHBmqHnP7617/Oww8/XLvn/pe//IWdO3c2+r22bt1Kjx49gOC4gIhIUygRNBMzY+7cubz44ov069ePIUOGcPnll/Ozn/2M8ePHU1ZWxuDBgzn++OO55pprmrSnfuutt/KDH/yAYcOG6WwjEWkyDUMt9dL6FWkADUMtIiKFRolARCTmiiYRFFoXV6HQehUpfkWRCNq1a0dNTY02Ws3M3ampqaFdu3b5DkVEIlQU1xH07NmTqqoqqqur8x1K0WnXrh09e/bMdxgiEqGiSARt2rT53NW5IiKSvaLoGhIRkcYrihaBiEiklk2DFbOzK/vBimCgygKiFoGISH1WzM5+VONu5VA+Jtp4mplaBCIi2ehWXu/VwoVKiUBE4qnIu3saQl1DIhJPRd7d0xBqEYhIfBVxd09DRNoiMLORZva2ma0xs9vSzO9tZgvM7A0ze9PMzosyHhEROVhkicDMSoAHgXOBMuBiMytLKXY78IS7DwLGAg9FFY+IiKQXZYtgCLDG3de6+15gJjA6pYwDHcPHnYD3I4xHRETSiDIR9AA2JD2vCqcluwO4zMyqgPnA9ekWZGZXm9kyM1um8YRERJpXlInA0kxLHR70YmC6u/cEzgMeM7ODYnL3ye5e4e4VXbt2jSBUEZH4ijIRVAG9kp735OCunyuBJwDcfTHQDugSYUwiIpIiytNHXwf6m1k/YCPBweBLUsq8B4wAppvZlwkSgfp+RKQgzVj6Hk9Xbsyq7KpN2yjr3rH+gjkQWYvA3fcD1wHPAqsJzg5aaWYTzWxUWOwm4Coz+xPwO+AK191lRKRAPV25kVWbtmVVtqx7R0YPTD1smh+RXlDm7vMJDgInT5uQ9HgVMCzKGEREcqmse0dmXXNKvsNoEA0xISISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnMahlpEioduNtMoSgQiUjwSN5vJZgOf5c1mCvUisYZQIhCR4pLFzWZqN+7LgeWLM5Zd+tdPABja78h637olXSTWEEoEIhI7iSuAs9l7H9rvSEYP7MElQ3vnILL8UCIQkVgqxCuAo6JEICIFL9HVM6FmKwATH8nc3VOofflR0emjIlLwGjLYGxRuX35U1CIQkaJQ1r0jA0o7ATBrnLp8GkItAhGRmFMiEBGJOSUCEZGY0zECEWmREmcCjdg1n2G7F2Qse/PeA7QvLQF7T8NGNIJaBCLSIiXOBBq2ewF9963NWLZ9aQldDmub9bAR8nlqEYhIi/XZmUCDGFDPsBHSeGoRiIjEnFoEItJ8GjIMdD0SVwmr3z96ahGISPNJDAPdnNTvHzm1CESkeWUxDHQ2EuMF6Srh6KlFICISc0oEIiIxp0QgIhJzOkYgIpnphvBFT4lAJI4asnFfvyj43+e0+svqDJ+CpEQgEkeJ0zyz2Xvvc1qwca8YF31ckhdKBCLFojFdOBq2QYg4EZjZSOB+oAR41N0npSnzLeAOwIE/ufslUcYkUlDUhSM5EFkiMLMS4EHgbKAKeN3M5rn7qqQy/YEfAMPcfbOZHRVVPCIFSV04kgNRtgiGAGvcfS2Amc0ERgOrkspcBTzo7psB3P2jCOMRKUzqwpGIRXkdQQ9gQ9LzqnBasi8CXzSzV8xsSdiVdBAzu9rMlpnZsurq6ojCFRGJpygTgaWZ5inPWwP9geHAxcCjZnb4QS9yn+zuFe5e0bVr12YPVEQkzqJMBFVAr6TnPYH305R52t33uftfgbcJEoOIiORIlIngdaC/mfUzs1JgLDAvpcxc4CwAM+tC0FWU+Z50IiLSrCJLBO6+H7gOeBZYDTzh7ivNbKKZjQqLPQvUmNkqYAFwi7vXRBWTiIgcLNLrCNx9PjA/ZdqEpMcOfD/8E5EiN2PpezxduTGrsqs2baOse8eIIxLQ6KMikkNPV25k1aZtWZUt696R0QNTTzSUKGiICRHJqbLuHZl1je461pKoRSAiEnNKBCIiMadEICISc0oEIiIx1+BEYGYlZnZpFMGIiEju1ZkIzKyjmf3AzB4ws3MscD3Blb/fyl2IIiISpUynjz4GbAYWA+OBW4BSYLS7V+YgNhHJg4Zc9NVQukisZcqUCI5x93IAM3sU+Bjo7e7bcxKZiORF4qKvKDbYukisZcqUCPYlHrj7ATP7q5KASDzooq94yZQITjSzbXx2X4FDkp67u6t9JyJSBOpMBO5ekstAREQkP+pMBGbWDrgWOBZ4E5gaDi0tIk2xbFpwU/psZHvjepEmyNQ19N8ExwleBs4DBgD/kougRIraitnZb+C7lUP5mCa/pYZ/lkwyJYKypLOGpgCv5SYkkQLUmL38cX+INqYkDTkTSGf2xE+2Zw3tN0t3L3qR+Em3dz2hZgp9961lXZtjslhCb17ZMpjnH1kcTYBpJJKAzgSSdDIlgoHhWUIQnCmks4ZEqHvvel2bY5jY+d48RZWZ9vIlk0yJ4E/uPihnkYgUkIP2rqd1AmDWOO1xS+HJlAg8Z1GIRCCqoRJ0MFWKTaZEcJSZ1XlTeXe/L4J4RJpNVEMlqJtFik2mRFACHMZnVxaLFJwmHyCt62ygVeFfgs73lwKWKRFscveJOYtEJFcacqrn+kXB/z6nZS7XTOf7i+RDpkSgloAUp4Zc0NXntGADXzEu+rhE8iRTIhiRsyhEstDQg78Zjw/k+IIukZaszjuUufsnuQxEpD6Jg7/Z0kFdkexkahGItDi6Olak+TX45vUiIlJclAhERGJOiUBEJOaUCEREYi7SRGBmI83sbTNbY2a3ZSg3xszczCqijEdERA4WWSIwsxLgQeBcoAy42MzK0pTrANwALI0qFhERqVuULYIhwBp3X+vue4GZwOg05X4K3APsiTAWERGpQ5SJoAewIel5VTitlpkNAnq5++8zLcjMrjazZWa2rLq6uvkjFRGJsSgTQbqximrvcWBmrYD/AG6qb0HuPtndK9y9omvXrs0YooiIRHllcRXQK+l5T+D9pOcdgOOBheH9kLsB88xslLsvizAuKUaNuXm8iADRJoLXgf5m1g/YCIwFLknMdPetQJfEczNbCNysJCC1UjbuE2q2Bg/C20J+TrbDRYOGjBZJEVkicPf9ZnYd8CzBTW6muvtKM5sILHP3eVG9t+RXplFCR+yaz7DdC7JazoC9KwBYWRrsve/ae4D2pSXpC2u4aJFGi3TQOXefD8xPmTahjrLDo4xFcifTLSKH7V5A331rWdfmmHqXs7K0nFcOOYvn259XO230wB4MGNq7WeMViTuNPiqRqHOU0GmdgEEMyPJeAAOAq5s1MhFJpSEmRERiTolARCTmlAhERGJOiUBEJOaUCEREYk5nDUnTNeTCL13VK9LiqEUgTbdidrCBz4au6hVpcdQikObRrRzCawMmPrIYgFnj0lxHICItjloEIiIxp0QgIhJzSgQiIjGnYwRx05Bx+7OlM4FECppaBHHTkDN8sqUzgUQKmloEcZR0ho+IiFoEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJzuqCsiMxY+h5PV27MWCZx05jEUNFRWLVpG2XdO0a2fBFpXkoExSAcP+jETVvpv/cA7UtL6izad99a1rU5JtJwyrp3ZPTAHpG+h4g0HyWCYlA7flBv2peWMKB7mltE1hrEgPIxzKrQTWNEJKBE0FI1ZJTQcPTPiXtvB3RnMBFpGB0sbql0H2ARyRG1CFqyho4Sujy6A8AiUrzUIhARiblIE4GZjTSzt81sjZndlmb+981slZm9aWbPm1mfKOMREZGDRZYIzKwEeBA4FygDLjazspRibwAV7n4CMBu4J6p4REQkvSiPEQwB1rj7WgAzmwmMBlYlCrj7gqTyS4DLIown/xpxJpCISNSi7BrqAWxIel4VTqvLlcAz6WaY2dVmtszMllVXVzdjiDmmM4FEpAWKskVgaaZ52oJmlwEVwJnp5rv7ZGAyQEVFRdplFAzdL1hEWpgoE0EV0CvpeU/g/dRCZvY14N+AM9390wjjERGRNKLsGnod6G9m/cysFBgLzEsuYGaDgEeAUe7+UYSxiIhIHSJLBO6+H7gOeBZYDTzh7ivNbKKZjQqL3QscBjxpZpVmNq+OxYmISEQivbLY3ecD81OmTUh6/LUo319EROqnK4tFRGJOiUBEJOaUCEREYk6JQEQk5pQIRERiTolARCTmlAhERGJOiUBEJOZ0q8oWbsbS93i6cmNWZVdt2kZZ944RRyQixUYtghbu6cqNrNq0LauyZd07MnpgppG+RUQOphZBASjr3pFZ15yS7zBEpEipRSAiEnNKBCIiMadEICISczpGkGMfbt/DDY8szrq8zgQSkaipRZBjH+/4NOuzgEBnAolI9NQiyAOdBSQiLYlaBCIiMadEICISc+oaaqpl02DF7OzKfrAC6B1pOCIiDaUWQVOtmB1u4LPQrZxXDjkr2nhERBpILYLm0K0cxv0hq6LPN+DUURGRXFCLQEQk5pQIRERiTolARCTmlAhERGJOiUBEJOZ01lAdsr1F5ISarQBMzPJsIA0iJyItjVoEdWjILSIbQoPIiUhLoxZBBlkNDjetEwCzxmkQOREpTLFKBNl294C6cEQkPiJNBGY2ErgfKAEedfdJKfPbAr8BTgJqgIvcfV1U8SS6e+rbwI/YNZ8JpQvo8mlbmNYu80I/WBFcWSwiUqAiSwRmVgI8CJwNVAGvm9k8d1+VVOxKYLO7H2tmY4GfARdFFRNk291zJ+x5DzpksYHvVg7lY5onOBGRPIiyRTAEWHunUFYAAAYVSURBVOPuawHMbCYwGkhOBKOBO8LHs4EHzMzc3Zs9mmduY0LNouBx2K9fp8RefpbjB4mIFLIozxrqAWxIel4VTktbxt33A1uBzqkLMrOrzWyZmS2rrq5udECHlrbm0NIscp/28kUkRqJsEViaaal7+tmUwd0nA5MBKioqGtdaOHcSfc9t1CtFRIpalC2CKqBX0vOewPt1lTGz1kAn4JMIYxIRkRRRJoLXgf5m1s/MSoGxwLyUMvOAy8PHY4AXIjk+ICIidYqsa8jd95vZdcCzBKePTnX3lWY2EVjm7vOAKcBjZraGoCUwNqp4REQkvUivI3D3+cD8lGkTkh7vAb4ZZQwiIpKZxhoSEYk5JQIRkZhTIhARiTklAhGRmLNCO1vTzKqB9UmTugAf5ymcfItz3SHe9Vfd46kpde/j7l3TzSi4RJDKzJa5e0W+48iHONcd4l1/1V11b07qGhIRiTklAhGRmCuGRDA53wHkUZzrDvGuv+oeT5HUveCPEYiISNMUQ4tARESaQIlARCTmCiYRmNlIM3vbzNaY2W1p5rc1s1nh/KVm1jf3UUYji7p/38xWmdmbZva8mfXJR5xRqK/uSeXGmJmbWdGcVphN3c3sW+Fnv9LMZuQ6xqhk8Z3vbWYLzOyN8Ht/Xj7ijIKZTTWzj8zsrTrmm5n9Mlw3b5rZ4Ca/qbu3+D+CYazfBY4BSoE/AWUpZb4D/Dp8PBaYle+4c1j3s4D24eN/jlPdw3IdgJeAJUBFvuPO4efeH3gDOCJ8flS+485h3ScD/xw+LgPW5TvuZqz/GcBg4K065p8HPENwh8evAEub+p6F0iIYAqxx97XuvheYSXDj+2Sjgf8OH88GRphZulthFpp66+7uC9x9V/h0CcHd4IpBNp87wE+Be4A9uQwuYtnU/SrgQXffDODuH+U4xqhkU3cHOoaPO3Hw3Q8Llru/ROY7NY4GfuOBJcDhZta9Ke9ZKImg9ib3oapwWtoy7r4f2Ap0zkl00cqm7smuJNhbKAb11t3MBgG93P33uQwsB7L53L8IfNHMXjGzJWY2MmfRRSubut8BXGZmVQT3PLk+N6G1CA3dJtQr0hvTNKNsbnKfTZlClHW9zOwyoAI4M9KIcidj3c2sFfAfwBW5CiiHsvncWxN0Dw0naAW+bGbHu/uWiGOLWjZ1vxiY7u6/MLNTCO50eLy7/y368PKu2bd1hdIiqL3JfagnBzcFa8uYWWuC5mKm5lWhyKbumNnXgH8DRrn7pzmKLWr11b0DcDyw0MzWEfSXziuSA8bZfuefdvd97v5X4G2CxFDosqn7lcATAO6+GGhHMCBbHGS1TWiIQkkErwP9zayfmZUSHAyel1JmHnB5+HgM8IKHR1YKXL11D7tHHiFIAsXSTwz11N3dt7p7F3fv6+59CY6PjHL3ZfkJt1ll852fS3CiAGbWhaCraG1Oo4xGNnV/DxgBYGZfJkgE1TmNMn/mAd8Ozx76CrDV3Tc1ZYEF0TXk7vvN7DrgWYIzCqa6+0ozmwgsc/d5wBSC5uEagpbA2PxF3HyyrPu9wGHAk+Hx8ffcfVTegm4mWda9KGVZ92eBc8xsFXAAuMXda/IXdfPIsu43Af9lZjcSdItcUSQ7fpjZ7wi6+7qEx0B+DLQBcPdfExwTOQ9YA+wCxjX5PYtk3YmISCMVSteQiIhERIlARCTmlAhERGJOiUBEJOaUCEREYk6JQCRLZnbAzCqT/vqa2XAz2xqOgrnazH4clk2e/mcz+3m+4xepS0FcRyDSQux294HJE8Lhzl929/PN7FCg0swS4x4lph8CvGFmc9z9ldyGLFI/tQhEmom77wSWA19Imb4bqKSJA4OJREWJQCR7hyR1C81JnWlmnQnGO1qZMv0IgjGAXspNmCINo64hkewd1DUUOt3M3gD+BkwKh0MYHk5/E/hSOP2DHMYqkjUlApGme9ndz69rupl9EVgUHiOozHVwIvVR15BIxNz9L8DdwL/mOxaRdJQIRHLj18AZZtYv34GIpNLooyIiMacWgYhIzCkRiIjEnBKBiEjMKRGIiMScEoGISMwpEYiIxJwSgYhIzP1/1BIfcUORgbYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def roc(dataset, train, test, laplace, positive, negative):\n",
    "    p_counts=[]\n",
    "    n_counts=[]\n",
    "    p=0\n",
    "    n=0\n",
    "    total=test.shape[0]\n",
    "    for r in range(total):\n",
    "        predicted=naive_bayes(dataset, train, test[r][0:-1], laplace)\n",
    "        real=test[r][-1]\n",
    "        if (predicted==positive) and (real==positive):\n",
    "            p+=1\n",
    "        elif (predicted==negative) and (real==positive):\n",
    "            n+=1\n",
    "        p_counts.append(p)\n",
    "        n_counts.append(n)\n",
    "    tpr=np.array(p_counts)/p\n",
    "    fpr=np.array(n_counts)/n\n",
    "    return(tpr, fpr)\n",
    "\n",
    "tpr_tic, fpr_tic = roc(tictac, train_tic, test_tic, True, \"positive\", \"negative\")\n",
    "tpr_german, fpr_german = roc(german, train_german, test_german, True, 1, 2)\n",
    "print(tpr_tic)\n",
    "plt.figure\n",
    "plt.plot(fpr_tic, tpr_tic, label=\"Tic tac toe\")\n",
    "plt.plot(fpr_german, tpr_german, label=\"German\")\n",
    "plt.title(\"Curvas ROC para clasificador de la práctica\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El area debajo de la curva ROC es mayor para el conjunto de datos de german, el clasificador discrimina las clases un poco mejor, que para el conjunto de datos tic-tac-toe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
