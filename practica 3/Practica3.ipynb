{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic atributes\n",
      "Pclass [1 2 3]\n",
      "Sex ['female' 'male']\n",
      "Age [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Class [0 1]\n",
      "\n",
      "Tic-tac-toe atributes\n",
      "TLeftSq ['b' 'o' 'x']\n",
      "TMidSq ['b' 'o' 'x']\n",
      "TRightSq ['b' 'o' 'x']\n",
      "MLeftSq ['b' 'o' 'x']\n",
      "MMidSq ['b' 'o' 'x']\n",
      "MRightSq ['b' 'o' 'x']\n",
      "BLeftSq ['b' 'o' 'x']\n",
      "BMidSq ['b' 'o' 'x']\n",
      "BRightSq ['b' 'o' 'x']\n",
      "Class ['negative' 'positive']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filename_titanic=\"titanic.data\"\n",
    "data_titanic = pd.read_csv(filename_titanic)\n",
    "\n",
    "filename_tic=\"tic-tac-toe.data\"\n",
    "\n",
    "data_tic=pd.read_csv(filename_tic)\n",
    "\n",
    "print(\"Titanic atributes\")\n",
    "for c in data_titanic.columns:\n",
    "    print(c, np.unique(data_titanic[c]))\n",
    "    \n",
    "print(\"\\nTic-tac-toe atributes\")\n",
    "for c in data_tic.columns:\n",
    "    print(c, np.unique(data_tic[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class AlgoritmoGenetico:\n",
    "    def __init__(self,train_set, diccionario, n_ind):\n",
    "        self.train=train_set.copy(deep=True)\n",
    "        self.diccionario=diccionario\n",
    "        self.encoder_length=0\n",
    "        self.class_length=len(self.diccionario[-1].values())\n",
    "        self.population_size=n_ind\n",
    "        for c in self.diccionario:\n",
    "            self.encoder_length+=len(c.values())\n",
    "        self.population=self.generate_population(n_ind)\n",
    "        self.train_encoded=self.encode(train_set)\n",
    "        \n",
    "    def rand_key(self,p):  #Return random 0-1 string of fixed size\n",
    "        key1 = \"\" \n",
    "        for i in range(p): \n",
    "            temp = str(random.randint(0, 1)) \n",
    "            key1 += temp \n",
    "        return(key1) \n",
    "    \n",
    "    def generate_population(self,n): #Generates a new random population of size n\n",
    "        population=[]\n",
    "        for i in range(n):\n",
    "            individual=self.rand_key(self.encoder_length)\n",
    "            population.append(individual)\n",
    "        return(population)\n",
    "    \n",
    "    def encode(self, rows):\n",
    "        train_encoded=[]\n",
    "        for index, row in rows.iterrows():\n",
    "            row_encoded=\"0\"*self.encoder_length\n",
    "            i=0\n",
    "            for idx, at in enumerate(row.values):\n",
    "                block_pos=self.diccionario[idx][at]\n",
    "                row_encoded=row_encoded[:i+block_pos]+\"1\"+row_encoded[i+block_pos+1:]\n",
    "                i=i+len(self.diccionario[idx])\n",
    "            train_encoded.append(row_encoded)\n",
    "        return(train_encoded)\n",
    "    \n",
    "    def encode_classify(self, rows):\n",
    "        train_encoded=[]\n",
    "        for index, row in rows.iterrows():\n",
    "            row_encoded=\"0\"*(self.encoder_length-self.class_length)\n",
    "            i=0\n",
    "            for idx, at in enumerate(row.values):\n",
    "                block_pos=self.diccionario[idx][at]\n",
    "                row_encoded=row_encoded[:i+block_pos]+\"1\"+row_encoded[i+block_pos+1:]\n",
    "                i=i+len(self.diccionario[idx])\n",
    "            train_encoded.append(row_encoded)\n",
    "        return(train_encoded)\n",
    "    \n",
    "    def convert_train_ints(self):  #This converts encoded binary train data set from strings to ints\n",
    "        train_ints=[]\n",
    "        for t in self.train_encoded:\n",
    "            train_ints.append(int(t[:-self.class_length],2))\n",
    "        return(train_ints)\n",
    "    \n",
    "    def count_fitness(self):\n",
    "        #convert train attributes to ints for bitwise operations\n",
    "        train_ints=self.convert_train_ints()\n",
    "        classes_t=[]\n",
    "        fitness=[]\n",
    "        #Filtering classes of the train cromosomes\n",
    "        for t in self.train_encoded:\n",
    "            classes_t.append(t[-self.class_length:])\n",
    "        i=0\n",
    "        for individual in self.population:\n",
    "            individual_rule=individual[:-self.class_length]  #Filter only the part of the conditions\n",
    "            individual_rule_int=int(individual_rule,2) #Converting binary string to int for bitwise operations\n",
    "            induvidual_class=individual[-self.class_length:] #The class of the individual cromosome\n",
    "            rule_counter=0 \n",
    "            rule_classes=[]\n",
    "            for t in range(len(train_ints)): #Comparing the indivudual rules with the train set\n",
    "                apply_mask=individual_rule_int|train_ints[t] #Or operator will return the same value as indivudual if the rule includes the train condition\n",
    "                if apply_mask==individual_rule_int:\n",
    "                    rule_counter+=1 #Counts how many training set rows correspond to the conditions programed in the individual\n",
    "                    rule_classes.append(classes_t[t]) #Stores the real class of the condition\n",
    "            rule_classes=np.array(rule_classes)\n",
    "            assert_class=len(rule_classes[rule_classes==induvidual_class]) #Calculates how many times the idividual predicted the right class\n",
    "            fitness.append(assert_class/(rule_counter+1)) #Fitness is the number of right classes divided by the number of apperances+1 of the individual's condition in the train dataset\n",
    "            #fitness.append(assert_class/len(train_ints))\n",
    "            i+=1\n",
    "        return(fitness)\n",
    "    \n",
    "    def choose_parents(self, elite_percent):\n",
    "        fitness=np.array(self.count_fitness())\n",
    "        fitness_sum=np.sum(fitness)\n",
    "        max_fit_id=np.argmax(fitness)\n",
    "        fitness_prop=fitness/fitness_sum\n",
    "        fitness_cdf=np.cumsum(fitness_prop)\n",
    "        elite_num=round(elite_percent*self.population_size)\n",
    "        elite_counter=0\n",
    "        parents=[]\n",
    "        parent_ids=[]\n",
    "        rand_sel=[]\n",
    "        for i in range(self.population_size):\n",
    "            if elite_counter<elite_num:  #Adding the elites without random selection\n",
    "                parents.append(self.population[max_fit_id])\n",
    "                elite_counter+=1\n",
    "            else:\n",
    "                r=np.random.rand() #Adding the rest based on their fitness\n",
    "                rand_sel.append(r)\n",
    "                ind_ids=np.where(fitness_cdf>=r)[0]\n",
    "                parent_ids.append(ind_ids[0])\n",
    "                parents.append(self.population[ind_ids[0]])\n",
    "        return(parents) \n",
    "    \n",
    "    def cross_one_point(self,parent1, parent2):\n",
    "        pos=np.random.randint(0,self.encoder_length)\n",
    "        child1=parent1[:pos]+parent2[pos:]\n",
    "        child2=parent2[:pos]+parent1[pos:]\n",
    "        return(child1, child2)\n",
    "    \n",
    "    def mutate(self, generation, mutation_prob):\n",
    "        mut_n=round(self.population_size*self.encoder_length*mutation_prob) #number of mutations in population\n",
    "        rand_n=np.random.rand(mut_n)\n",
    "        m_pos=rand_n*self.population_size*self.encoder_length #gerenating random positions of mutations\n",
    "        idx,p=divmod(m_pos,self.encoder_length) #determinings individuals and the position in the cromosome\n",
    "        p=np.round(p)\n",
    "        idx=idx.astype(int)\n",
    "        p=p.astype(int)\n",
    "        #print(\"Mutations where done at\", idx, p)\n",
    "        for i in range(mut_n):\n",
    "            if p[i]==self.encoder_length: \n",
    "                p[i]=p[i]-1\n",
    "            ind=generation[idx[i]]\n",
    "            ind_list=list(ind)\n",
    "            #print(ind_list, p[i])\n",
    "            if ind_list[p[i]]==\"1\":\n",
    "                ind_list[p[i]]=\"0\"\n",
    "            else:\n",
    "                ind_list[p[i]]=\"1\"\n",
    "            ind=\"\".join(ind_list)\n",
    "            generation[idx[i]]=ind\n",
    "        return(generation)\n",
    "    \n",
    "    def generate_next_population(self,elite_percent, mutation_prob, mutate):\n",
    "        parents=self.choose_parents(elite_percent)\n",
    "        couples_num=round(self.population_size/2)\n",
    "        next_generation=[]\n",
    "        for i in range(couples_num):\n",
    "            child1,child2=self.cross_one_point(parents[i], parents[i+2])\n",
    "            next_generation.append(child1)\n",
    "            next_generation.append(child2)\n",
    "        #print(\"Next generation before mutation:\", next_generation)\n",
    "        if mutate:\n",
    "            next_generation=self.mutate(next_generation, mutation_prob)\n",
    "        self.population=next_generation\n",
    "        return(next_generation)\n",
    "    \n",
    "    def training(self, iteractions, elite_percent, mutation_prob):\n",
    "        for i in range(iteractions):\n",
    "            if i!=iteractions-1:\n",
    "                generation=self.generate_next_population(elite_percent, mutation_prob, True)\n",
    "            else:\n",
    "            #Avoid mutations in last generation\n",
    "                generation=self.generate_next_population(elite_percent, mutation_prob, False)\n",
    "            #print(\"Generation #\", i+1, generation)\n",
    "        #Return unique rules:\n",
    "        id_best=np.argmax(self.count_fitness())\n",
    "        self.rule=self.population[id_best]\n",
    "        self.rules=np.unique(self.population)\n",
    "        return(self.rule)\n",
    "\n",
    "    def classify1(self, rows):  #The test one to check classification with all generated rules\n",
    "        rows_encoded=self.encode_classify(rows)\n",
    "        #rule_cond=self.rule[:-self.class_length]\n",
    "        #rule_class=self.rule[-self.class_length:]\n",
    "        #print(rule_class)\n",
    "        #print(row_encoded, rule_cond, rule_class)\n",
    "        #rule_int=int(rule_cond,2)\n",
    "        self.err=0\n",
    "        classes=[]\n",
    "        for r in rows_encoded:\n",
    "            row_int=int(r,2)\n",
    "            #apply_mask=rule_int|row_int\n",
    "            classes=[]\n",
    "            class_id=[]\n",
    "            classe_names=[]\n",
    "            for rule in self.rules:\n",
    "                #print(rule)\n",
    "                rule_cond=self.rule[:-self.class_length]\n",
    "                rule_class=self.rule[-self.class_length:] \n",
    "                rule_int=int(rule_cond,2)\n",
    "                apply_mask=rule_int|row_int\n",
    "                cl_id=rule_class.find(\"1\")\n",
    "                if apply_mask==rule_int:\n",
    "                    class_id.append(rule_class)\n",
    "                    class_name=self.diccionario[-1][cl_id]\n",
    "                    classe_names.append(class_name)\n",
    "                else:\n",
    "                    cls=self.diccionario[-1]\n",
    "                    #print(\"Class id\", cl_id, cls[0])\n",
    "                    if cl_id==0:\n",
    "                        class_name=self.diccionario[-1][1]\n",
    "                    else:\n",
    "                        class_name=self.diccionario[-1][0]\n",
    "                    classe_names.append(class_name)\n",
    "                        \n",
    "                    #class_id.append(\"Other\")\n",
    "                    #print(\"wrong class\")\n",
    "            print(r, classe_names)\n",
    "            classes.append(class_id)\n",
    "    def classify(self, rows): #Classifies with the rule that has best fitness\n",
    "        rows_encoded=self.encode_classify(rows)\n",
    "        classes_dict=self.diccionario[-1]\n",
    "        classes=[]\n",
    "        for r in rows_encoded:\n",
    "            row_int=int(r,2)\n",
    "            rule_cond=self.rule[:-self.class_length]\n",
    "            rule_class=self.rule[-self.class_length:] \n",
    "            rule_int=int(rule_cond,2)\n",
    "            apply_mask=rule_int|row_int\n",
    "            cl_id=rule_class.find(\"1\")\n",
    "            if apply_mask==rule_int:\n",
    "                class_name=list(classes_dict.keys())[list(classes_dict.values()).index(cl_id)]\n",
    "            else:\n",
    "                if cl_id==0:\n",
    "                    class_name=list(classes_dict.keys())[list(classes_dict.values()).index(1)]\n",
    "                else:\n",
    "                    class_name=list(classes_dict.keys())[list(classes_dict.values()).index(0)]\n",
    "            classes.append(class_name)\n",
    "        return(classes)\n",
    "    def error(self, test):\n",
    "        predicted_class=self.classify(test.iloc[:,:-1])\n",
    "        real_class=test.iloc[:,-1]\n",
    "        i=0\n",
    "        count=0\n",
    "        for c in real_class:\n",
    "            if c==predicted_class[i]:\n",
    "                count+=1\n",
    "            i+=1\n",
    "        err=1-count/test.shape[0]\n",
    "        return(err)\n",
    "        \n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1: 0, 2: 1, 3: 2}, {'female': 0, 'male': 1}, {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15}, {0: 0, 1: 1}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10010011101101011010101\n",
      "Error 0.3336520076481836\n"
     ]
    }
   ],
   "source": [
    "from Datos import *\n",
    "dataset_titanic=Datos(filename_titanic)\n",
    "\n",
    "tit_dic=dataset_titanic.diccionario\n",
    "print(tit_dic)\n",
    "titanic=AlgoritmoGenetico(data_titanic,tit_dic, 150)\n",
    "\n",
    "#train_encoded=titanic.encode(data_titanic)\n",
    "rule=titanic.training(100,0.05, 0.01)\n",
    "\n",
    "#print(titanic.rules)\n",
    "#print(titanic.count_fitness())\n",
    "print(rule)\n",
    "\n",
    "\n",
    "cl=titanic.classify(data_titanic.iloc[:,:-1])\n",
    "\n",
    "print(\"Error\", titanic.error(data_titanic))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01001001000010111011010\n",
      "Error 0.5592734225621414\n"
     ]
    }
   ],
   "source": [
    "#we try with 50 population instead of 150, 100 epochs\n",
    "titanic=AlgoritmoGenetico(data_titanic,tit_dic, 50)\n",
    "\n",
    "rule=titanic.training(100,0.05, 0.01)\n",
    "\n",
    "print(rule)\n",
    "\n",
    "\n",
    "cl=titanic.classify(data_titanic.iloc[:,:-1])\n",
    "\n",
    "print(\"Error\", titanic.error(data_titanic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10010001101101011010101\n",
      "Error 0.3336520076481836\n"
     ]
    }
   ],
   "source": [
    "#we try with 200 epochs instead of 100, 150 population\n",
    "titanic=AlgoritmoGenetico(data_titanic,tit_dic, 150)\n",
    "\n",
    "rule=titanic.training(200,0.05, 0.01)\n",
    "\n",
    "print(rule)\n",
    "\n",
    "\n",
    "cl=titanic.classify(data_titanic.iloc[:,:-1])\n",
    "\n",
    "print(\"Error\", titanic.error(data_titanic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01001001000010111010010\n",
      "Error 0.5592734225621414\n"
     ]
    }
   ],
   "source": [
    "#we try with 50 population instead of 150 AND 200 epochs instead of 100\n",
    "titanic=AlgoritmoGenetico(data_titanic,tit_dic, 50)\n",
    "\n",
    "rule=titanic.training(200,0.05, 0.01)\n",
    "\n",
    "print(rule)\n",
    "\n",
    "\n",
    "cl=titanic.classify(data_titanic.iloc[:,:-1])\n",
    "\n",
    "print(\"Error\", titanic.error(data_titanic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el conjunto de datos del Titanic, observamos que el algoritmo se beneficia de un mayor número de épocas o población. Sin embargo, juzgando por los resultados, podemos afirmar que la población tiene bastante más peso, ya que todas las pruebas con un valor grande de ésta dan errores menores aunque el número de épocas objetivo sea reducido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'b': 0, 'o': 1, 'x': 2}, {'b': 0, 'o': 1, 'x': 2}, {'b': 0, 'o': 1, 'x': 2}, {'b': 0, 'o': 1, 'x': 2}, {'b': 0, 'o': 1, 'x': 2}, {'b': 0, 'o': 1, 'x': 2}, {'b': 0, 'o': 1, 'x': 2}, {'b': 0, 'o': 1, 'x': 2}, {'b': 0, 'o': 1, 'x': 2}, {'negative': 0, 'positive': 1}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111110111110111110111111101\n",
      "Error 0.4279749478079332\n"
     ]
    }
   ],
   "source": [
    "dataset_tic=Datos(filename_tic)\n",
    "#print(row, data_titanic.iloc[[1],-1])\n",
    "tic_dic=dataset_tic.diccionario\n",
    "print(tic_dic)\n",
    "tictoc=AlgoritmoGenetico(data_tic,tic_dic, 150)\n",
    "\n",
    "rule=tictoc.training(100,0.05, 0.01)\n",
    "\n",
    "print(rule)\n",
    "\n",
    "cl=tictoc.classify(data_tic.iloc[:,:-1])\n",
    "#print(cl)\n",
    "print(\"Error\", tictoc.error(data_tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111100111111100111111100101\n",
      "Error 0.5720250521920668\n"
     ]
    }
   ],
   "source": [
    "#we try with 50 population instead of 150, 100 epochs\n",
    "tictoc=AlgoritmoGenetico(data_tic,tic_dic, 50)\n",
    "\n",
    "rule=tictoc.training(100,0.05, 0.01)\n",
    "\n",
    "print(rule)\n",
    "\n",
    "cl=tictoc.classify(data_tic.iloc[:,:-1])\n",
    "#print(cl)\n",
    "print(\"Error\", tictoc.error(data_tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10111111111110111111111110101\n",
      "Error 0.4279749478079332\n"
     ]
    }
   ],
   "source": [
    "#we try with 200 epochs instead of 100, 150 population\n",
    "tictoc=AlgoritmoGenetico(data_tic,tic_dic, 150)\n",
    "\n",
    "rule=tictoc.training(200,0.05, 0.01)\n",
    "\n",
    "print(rule)\n",
    "\n",
    "cl=tictoc.classify(data_tic.iloc[:,:-1])\n",
    "#print(cl)\n",
    "print(\"Error\", tictoc.error(data_tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10111111111110111111111110101\n",
      "Error 0.4279749478079332\n"
     ]
    }
   ],
   "source": [
    "#we try with 50 population instead of 150 AND 200 epochs instead of 100\n",
    "tictoc=AlgoritmoGenetico(data_tic,tic_dic, 50)\n",
    "\n",
    "rule=tictoc.training(200,0.05, 0.01)\n",
    "\n",
    "print(rule)\n",
    "\n",
    "cl=tictoc.classify(data_tic.iloc[:,:-1])\n",
    "#print(cl)\n",
    "print(\"Error\", tictoc.error(data_tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el conjunto de datos tic-tac-toe, el algoritmo parece haber convergido, o haberse saturado completamente, si los valores son suficientemente altos, ya que excepto la prueba con ambos valores inferiores (50 de población, 100 épocas) se muestra el mismo error, sin ninguna mejora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
